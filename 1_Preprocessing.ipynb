{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3f4b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================\n",
    "# Data Preprocessing\n",
    "# Outputs (under ./data)\n",
    "# ===============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(\"./data\")\n",
    "\n",
    "TRAIN_PATH = DATA_DIR / \"train.csv\"\n",
    "TEST_PATH = DATA_DIR / \"test.csv\"\n",
    "\n",
    "TRAIN_PREPROCESSED_PATH = DATA_DIR / \"train_preprocessed.csv\"\n",
    "TEST_PREPROCESSED_PATH = DATA_DIR / \"test_preprocessed.csv\"\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38102d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(dataset: pd.DataFrame, train=True) -> None:\n",
    "    dataset['TDateTimeOfAccident'] = pd.to_datetime(dataset['DateTimeOfAccident'], utc=True)\n",
    "    dataset['TDateReported'] = pd.to_datetime(dataset['DateReported'], utc=True)\n",
    "\n",
    "    dataset['accident_year'] = dataset['TDateTimeOfAccident'].dt.year\n",
    "    dataset['accident_month'] = dataset['TDateTimeOfAccident'].dt.month\n",
    "    dataset['accident_dow'] = dataset['TDateTimeOfAccident'].dt.dayofweek\n",
    "    dataset['accident_hour'] = dataset['TDateTimeOfAccident'].dt.hour\n",
    "    dataset['is_weekend'] = dataset['accident_dow'].isin([5, 6]).astype(int)\n",
    "\n",
    "    dataset['report_delay_days'] = (dataset['TDateReported'] - dataset['TDateTimeOfAccident']).dt.days\n",
    "\n",
    "    dataset['hourly_wage'] = dataset['WeeklyWages'] / dataset['HoursWorkedPerWeek']\n",
    "    dataset['hourly_wage'] = dataset['hourly_wage'].replace([0, np.inf, -np.inf], np.nan)\n",
    "    \n",
    "    dataset['iicc_is_one_flag'] = (dataset['InitialIncurredClaimsCost'] == 1).astype(int)\n",
    "    dataset['inconsistent_wages_flag'] = dataset[dataset['WeeklyWages'] > 0].index.isin((dataset[dataset['HoursWorkedPerWeek'] == 0].index)).astype(int)\n",
    "    dataset['invalid_exposure_flag'] = dataset[dataset['DaysWorkedPerWeek'] > 0].index.isin((dataset[dataset['HoursWorkedPerWeek'] == 0].index)).astype(int)\n",
    "    dataset['iicc_small_flag'] = (dataset['InitialIncurredClaimsCost'] < 100).astype(int)\n",
    "\n",
    "    dataset['logIICC'] = np.log1p(dataset['InitialIncurredClaimsCost'])\n",
    "\n",
    "    # Fill missing data\n",
    "    dataset['report_delay_days'] = dataset['report_delay_days'].apply(lambda x: 0 if x < 0 else x)\n",
    "    dataset['MaritalStatus'] = dataset['MaritalStatus'].fillna('U')\n",
    "\n",
    "    if train:\n",
    "        dataset['logUICC'] = np.log1p(dataset['UltimateIncurredClaimCost'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b85932c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw datasets\n",
    "df_train = pd.read_csv(TRAIN_PATH, delimiter=\",\")\n",
    "df_test = pd.read_csv(TEST_PATH, delimiter=\",\")\n",
    "\n",
    "preprocess(df_train)\n",
    "preprocess(df_test, False)\n",
    "\n",
    "# Dump preprocessed datasets\n",
    "df_train.to_csv(TRAIN_PREPROCESSED_PATH, index=False)\n",
    "df_test.to_csv(TEST_PREPROCESSED_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc0d790",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
